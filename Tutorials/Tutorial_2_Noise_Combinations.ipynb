{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "import anndata as ad\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['R_HOME'] = 'E:/R-4.3.1'\n",
    "os.environ['R_USER'] = 'E:/anaconda/lib/site-packages/rpy2'\n",
    "import sys\n",
    "sys.path.append(r'D:/study/learning\\spatial_transcriptome/papers\\spatial_multi_omics-main')\n",
    "from Model.utils import mclust_R\n",
    "from Model.model import DCCAE\n",
    "from Model.preprocess import fix_seed\n",
    "fix_seed(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_anndata(adata):\n",
    "    \"\"\"\n",
    "    Expand the original AnnData object to a new AnnData object.\n",
    "    \n",
    "    Parameters:\n",
    "    adata (AnnData): The original AnnData object.\n",
    "    \n",
    "    Returns:\n",
    "    AnnData: The expanded AnnData object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the data from other levels\n",
    "    level_0_data = adata.uns['INR_level_0']\n",
    "    level_1_data = adata.uns['INR_level_1']\n",
    "    level_2_data = adata.uns['INR_level_2']\n",
    "    level_3_data = adata.uns['INR_level_3']\n",
    "\n",
    "    # Vertically stack the data\n",
    "    new_X = np.vstack([level_0_data, level_1_data, level_2_data, level_3_data])\n",
    "\n",
    "    # Create a new AnnData object\n",
    "    new_adata = ad.AnnData(X=new_X)\n",
    "    \n",
    "    # Drop the 'batch' column from the original obs\n",
    "    adata.obs = adata.obs.drop(columns=['batch'])\n",
    "    \n",
    "    # Create a 'noise' field for each part of the data\n",
    "    noise_values = np.repeat([0, 1, 2, 3], adata.n_obs)\n",
    "    \n",
    "    # Copy the original obs data and expand it\n",
    "    new_obs = pd.concat([adata.obs] * 4, ignore_index=True)\n",
    "    new_obs['noise_level'] = noise_values\n",
    "\n",
    "    new_adata.obs = new_obs\n",
    "    new_adata.obsm['spatial'] = np.vstack([adata.obsm['spatial']] * 4)\n",
    "    return new_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "replicate = 4\n",
    "file_fold_1 = f'D:/study/learning/spatial_transcriptome/papers/spatial_multi_omics-main/data/Noise_Combination_{replicate}/Combination{replicate}_RNA'\n",
    "file_fold_2 = f'D:/study/learning/spatial_transcriptome/papers/spatial_multi_omics-main/data/Noise_Combination_{replicate}/Combination{replicate}_Protein'\n",
    "\n",
    "adata_omics_1 = sc.read_h5ad(file_fold_1 + '.h5ad')\n",
    "adata_omics_2 = sc.read_h5ad(file_fold_2 + '.h5ad')\n",
    "\n",
    "adata_omics_1 = expand_anndata(adata_omics_1)\n",
    "adata_omics_2 = expand_anndata(adata_omics_2)\n",
    "\n",
    "noise_level = 3\n",
    "adata_omics_1 = adata_omics_1[adata_omics_1.obs['noise_level']==noise_level]\n",
    "adata_omics_2 = adata_omics_2[adata_omics_2.obs['noise_level']==noise_level]\n",
    "\n",
    "sc.pp.pca(adata_omics_1, use_highly_variable=False)\n",
    "sc.pp.pca(adata_omics_2, use_highly_variable=False)\n",
    "\n",
    "adata_RNA = adata_omics_1.copy()\n",
    "adata_ADT = adata_omics_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 100/100 [00:06<00:00, 16.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training finished!\n",
      "fitting ...\n",
      "  |                                                                      |   0%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n",
      "n=4, DCCA, ARI = 0.9176865006494802\n",
      "fitting ...\n",
      "  |======================================================================| 100%\n",
      "n=4, DCCA, ARI = 0.7608546403066153\n",
      "fitting ...\n",
      "  |======================================================================| 100%\n",
      "n=4, DCCA, ARI = 0.9136901477311118\n"
     ]
    }
   ],
   "source": [
    "# bandwidth=0.02, n_DCCA = 5, epochs = 100\n",
    "n_DCCA = 5\n",
    "\n",
    "features1 = adata_RNA.obsm['X_pca'].shape[1]  # Feature sizes\n",
    "features2 = adata_ADT.obsm['X_pca'].shape[1]\n",
    "layers1 = [256, 256, n_DCCA]  # nodes in each hidden layer and the output size\n",
    "layers2 = [256, 256, n_DCCA]\n",
    "X = adata_RNA.obsm['X_pca'].copy()\n",
    "Y = adata_ADT.obsm['X_pca'].copy()\n",
    "\n",
    "use_rep = ['DCCA_X', \"DCCA_Y\", \"DCCA\"]\n",
    "\n",
    "epochs = 100\n",
    "dcca = DCCAE(input_size1=features1, input_size2=features2, n_components=n_DCCA, layer_sizes1=layers1, layer_sizes2=layers2, epoch_num=epochs, learning_rate=0.001)\n",
    "dcca.fit([X, Y])\n",
    "Xs_transformed = dcca.transform([X, Y])\n",
    "adata_RNA.obsm[\"DCCA_X\"] =  Xs_transformed[0]\n",
    "adata_ADT.obsm[\"DCCA_Y\"] =  Xs_transformed[1]\n",
    "adata_RNA.obsm[\"DCCA\"] = np.concatenate((adata_RNA.obsm[\"DCCA_X\"], adata_ADT.obsm[\"DCCA_Y\"]),axis=1)\n",
    "\n",
    "n = 4\n",
    "\n",
    "mclust_R(adata_RNA, used_obsm='DCCA_X', num_cluster=n)\n",
    "obs_df = adata_RNA.obs.dropna()\n",
    "ARI = adjusted_rand_score(obs_df['clusters_mclust'], obs_df['Ground Truth'])\n",
    "print(f'n={n}, DCCA, ARI = {ARI}')\n",
    "\n",
    "mclust_R(adata_ADT, used_obsm='DCCA_Y', num_cluster=n)\n",
    "obs_df = adata_ADT.obs.dropna()\n",
    "ARI = adjusted_rand_score(obs_df['clusters_mclust'], obs_df['Ground Truth'])\n",
    "print(f'n={n}, DCCA, ARI = {ARI}')\n",
    "\n",
    "mclust_R(adata_RNA, used_obsm='DCCA', num_cluster=n)\n",
    "obs_df = adata_RNA.obs.dropna()\n",
    "ARI = adjusted_rand_score(obs_df['clusters_mclust'], obs_df['Ground Truth'])\n",
    "print(f'n={n}, DCCA, ARI = {ARI}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_0 = ad.AnnData(obs=adata_RNA.obs[['clusters_mclust', 'noise_level']], obsm={'SpaKnit': adata_RNA.obsm['DCCA']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_1 = ad.AnnData(obs=adata_RNA.obs[['clusters_mclust', 'noise_level']], obsm={'SpaKnit': adata_RNA.obsm['DCCA']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_2 = ad.AnnData(obs=adata_RNA.obs[['clusters_mclust', 'noise_level']], obsm={'SpaKnit': adata_RNA.obsm['DCCA']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_3 = ad.AnnData(obs=adata_RNA.obs[['clusters_mclust', 'noise_level']], obsm={'SpaKnit': adata_RNA.obsm['DCCA']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_results = adata_0.concatenate(adata_1, adata_2, adata_3, batch_key='noise_level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_df = adata_results.obs\n",
    "\n",
    "# 然后，重命名列名\n",
    "obs_df = obs_df.rename(columns={'clusters_mclust': 'SpaKnit'})\n",
    "\n",
    "# 最后，将修改后的DataFrame重新赋值给AnnData对象的obs属性\n",
    "adata_results.obs = obs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 4800 × 0\n",
       "    obs: 'SpaKnit', 'noise_level'\n",
       "    obsm: 'SpaKnit'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sc.read_h5ad(f'D:/study/learning/spatial_transcriptome/papers/spatial_multi_omics-main/Results/Noise_Combination_{replicate}.h5ad')\n",
    "\n",
    "results.obs['SpaKnit'] = adata_results.obs['SpaKnit'].values\n",
    "results.obsm['SpaKnit'] = adata_results.obsm['SpaKnit']\n",
    "results.write_h5ad(f'D:/study/learning/spatial_transcriptome/papers/spatial_multi_omics-main/Results/Noise_Combination_{replicate}.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 4800 × 0\n",
       "    obs: 'Ground Truth', 'noise_level', 'SpaGCN', 'SpatialGlue', 'MultiMAP', 'STAGATE', 'Modality1', 'Modality2', 'SpaKnit'\n",
       "    obsm: 'Modality1', 'Modality2', 'MultiMAP', 'STAGATE', 'SpatialGlue', 'spatial', 'SpaKnit'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
